window.searchIndex = [{"url":"https://yzzfo.github.io/","title":"Chsxy's Blog","description":null,"body":"Hello World.\n","path":null},{"url":"https://yzzfo.github.io/bookmarks/","title":"List of bookmarks","description":null,"body":"","path":null},{"url":"https://yzzfo.github.io/bookmarks/关于 Safari 100vh 的问题与解决方案/","title":"关于 Safari 100vh 的问题与解决方案","description":null,"body":"","path":null},{"url":"https://yzzfo.github.io/bookmarks/Alpha is Transparency的实现方式/","title":"The Texture2D equivalent of Alpha is Transparency for LoadImage png","description":null,"body":"\n","path":null},{"url":"https://yzzfo.github.io/bookmarks/揭开 baseline & line-height & vertical-align 的面纱/","title":"揭开 baseline & line-height & vertical-align 的面纱","description":null,"body":"","path":null},{"url":"https://yzzfo.github.io/blog/","title":"List of blog posts","description":null,"body":"","path":null},{"url":"https://yzzfo.github.io/blog/zola笔记/","title":"zola笔记","description":null,"body":"Zola的目录结构\n\nZola主题\n安装主题\n找到Zola的主题后，可以通过切换到themes路径将主题的仓库clone到themes文件夹内\nthemes和templates\ntemplates中的内容会覆盖themes/templates中的同名内容，可用于修改主题\n使用主题\n由于每个主题对section的处理都有区别，所以推荐直接clone主题仓库后在该仓库内运行zola serve来预览一下主题，在查看一下config.toml以及content中的结构，确定后，迁移config.toml到自己的博客内，同时适配自己的content结构。\n自定义主题\n模板引擎\nZola使用的是Tera模板，所以在使用的时候需要了解一些Tera模板的基础语法。\n模块\n\nsection  当content以及子文件夹中，每出现一个_index.md，即出现一个section\n\n\n\npage section文件夹下面的xxxx.md或者文件夹/index.md这样的形式为page\n\n\n两个section，三个page\n分类\n要使用分类，需要先在config.toml中设置taxonomies，这里用于添加类目例如(software,platform)\n这样就可以在page中设置page的software和platform这两个类目的信息\n\n\n搜索功能\nzola可以生成用于搜索的数据，通过build_search_index = true即可生成搜索用的json数据，使用时需要配合elasticlunr或者fuse.\n其他相关的文档链接\n\n内置变量\n内置函数\nOverview\n\nTailwild（可选）\n参考 https://www.printlnhello.world/blog/zola-tailwindcss/\n总结起来就是安装tailwindcss，在启动zola之前，先使用tailwind生成css到static文件夹内\n","path":null},{"url":"https://yzzfo.github.io/blog/将iPad作为Windos副屏的方案/","title":"将iPad作为Windos副屏的方案","description":null,"body":"  几年前尝试过将iPad作为副屏，但app store上的方案基本上都存在延迟过高，画面模糊的问题，今天研究了以下后发现了一些新的方案。\n串流+虚拟屏幕\n该方案在局域网的情况下延迟和画质都十分优秀，核心逻辑就是串流虚拟屏幕达到副屏的效果\n串流软件\n\nsunshine + moonlight\nrustdesk\ngameview\n\n虚拟屏幕\n\nParsecVDisplay  ( https://github.com/nomi-san/parsec-vdd )\n\n其他问题\nsunshine\n\n功耗过高，默认情况下sunshine使用了n卡的倾向于较低的编码延迟而不是省电导致空载功耗过高，需要将其禁用即可降低功耗，在sunshine的NVIDIA NVENC Encoder中可以找到该选项（ https://github.com/LizardByte/Sunshine/issues/1908 ）\n音频，如果不想将音频传输到iPad，可以将捕获的音频设备设置为一个不存在的设备。\n\nSunshine-Foundation\n该版本内置了虚拟屏幕驱动，且配置了hdr等一些高阶功能，可用于iPad进行hdr显示\nmoonlight-ios-NativeMultiTouchPassthrough\n该版本的moonlight可以处理iPad多点操作，apple pencil等，这样就可以作为一个可触摸的windows副屏\ngameview\n\n副屏无法显示鼠标指针，在控制端点击【操作】-【启用按键映射】-【切换操控方案】选择【办公常用】方案，并选择【屏幕触控】模式，开启完成后，鼠标就会在控制端显示出来；( https://feedback-web.webapp.163.com/qa_detail/331 )\n\n现成的副屏软件\n这些软件处于基本能用的状态，要求不高的情况下可以使用\n\nspacedesk整体速度和画面还算不错。\nduet和spacedesk差不多\n\n副屏Windos下的配置\n\n任务栏，可以通过个性化-任务栏-当使用多个显示器时，在以下位置显示我都任务栏应用设置为打开了窗口的任务栏，这样任务栏只会显示在当前屏幕中的任务。\n\n总结\n总体测试下来，Sunshine-Foundation+moonlight-ios-NativeMultiTouchPassthrough的效果是最理想的，组件的屏幕兼容触摸操作，配合apple pencil也可以作为数位板支持压感。\n","path":null},{"url":"https://yzzfo.github.io/blog/自动化玩游戏——模型训练/","title":"自动化玩游戏——模型训练","description":null,"body":"在搭建了Yolo环境后我们就需要训练自己的模型了，这是一个费时的事情，但我们可以通过某些方式来加快他的进程。\n训练基础模型\n训练基础模型的方法可以参考自动化玩游戏——Yolo一文中的内容\n使用基础模型生成带标注的数据\n\n使用labelimg编辑自动标注的文件\n用labelimg打开刚刚训练出的文件夹，对里面的标注进行纠正，也可以少量修正，训练时可用于增强模型的泛用性\n使用新数据训练新模型\n将刚刚新生成的数据加入数据集中，重新训练模型，循环往复即可\n参考\n\nPretrain YOLOv8 with semi-supervised learning\n\n","path":null},{"url":"https://yzzfo.github.io/blog/自动化玩游戏——Yolo/","title":"自动化玩游戏——搭建Yolo环境","description":null,"body":"Yolo现在主流有v5和v8两者在使用上还是有点差别的，v8整体来看比v5现代化许多。\n搭建v5\n由于v8中有些知识依赖v5，所以先搭建一个v5环境。\n\n训练模型\n经过上面的命令yolov5环境就算搭建好了，接下来就是训练模型。\n\n编辑标签文件\n在datas目录下有很多的yaml文件，以coco.yaml文件为例，我们需要在里面定义编号以及对应的名称。\n\n\n\n上面的yaml定义了train和val目录，yolo训练的时候会自动将images改为lables然后再里面去查找对应的标签。\n\n标记图片\n标记图片使用labelimg\n执行训练\n\n\n使用模型\n\n搭建v8\n\npip install ultralytics\n同v5中的datasets结构一致搭建数据集，并创建coco.yaml\n训练yolo train data=coco8.yaml model=yolov8n.pt epochs=10 lr0=0.01\n导出onnxyolo export model=yolov8n-cls.pt format=onnx\n\n使用模型\n\n在Rust中使用Yolov8模型\n  参考YOLOv8-ONNXRuntime-Rust\n\n安装onnxruntime环境，在Win11中默认的版本可能过低需要去下载新的onnxruntime\n查阅文档，看个版本支持的Cuda版本，例如此时1.18.1需要Cuda 12.x，cuDNN 9.x  ，下载后将dll放入rust工程根目录，同时安装对应版本的Cuda和cuDNN，两者都需要，否则可能导致onnx无法使用Cuda执行。\n编写build.rs\n\n\nYOLOv8-ONNXRuntime-Rust的作者的更新基本在usls，可参考该处看更多内容。\n","path":null},{"url":"https://yzzfo.github.io/blog/自动化玩游戏——输入控制/","title":"自动化玩游戏——输入控制","description":null,"body":"  最近在制作自动搬砖的程序时遇到程序发送的输入事件游戏无法接收到，在查阅了相关资料后发现这应该是由于游戏是直接使用dx直接读取的信号输入，没有经过系统的信号输入事件，而通常的输入库只是往系统输入事件中发送消息，所以导致游戏无法读取到程序发送的输入事件。经过一番搜索找到如下几个库对其作了相应处理。\n\nhttps://github.com/ReggX/pydirectinput_rgx\nhttps://github.com/pentamassiv/enigo/tree/win_respect_lang\nhttps://raw.githubusercontent.com/SilverComet7/yolov5-DNF/main/directkeys.py\n这两个库都在发送系统消息的同时也发送ScanCode，通过这种方式来解决输入问题\n\n在使用这些库的同时还需要管理员权限运行才能正常获取到输入\n参考资料\n\nhttps://www.bilibili.com/read/cv13574363/\n\n","path":null},{"url":"https://yzzfo.github.io/blog/在Unity中实现Illustrator中的文本排版/","title":"在Unity中实现Illustrator中的文本排版","description":null,"body":"最近需要在Unity中实现和Illustrator中一样的文本渲染效果，但Unity的TextMeshPro和Illustrator差别还是蛮大的，所以在这记录一下相关的内容。\n\n在横版的情况下\n如何确定字体高度\n  有时候我们将fontSize设置为12px的时候却发现他的preferHeight却是14px，那么这是怎么来的呢？为了明白这个问题，我们需要先知道字体中的三个基础属性:\n\nUPM：Units per Em，通常为1000，fontSize将对应该值，可以理解为标准字体大小\nAscent: 上界距离基线的距离\nDescent: 下界距离基线的距离\n\nAscent与Descent组合在一起用于确定字体最大的高度Height=Ascent-Descent，preferHeight对应该值。所以可以得到height_px = Height / UPM * fontsize_px，这点在Unity和Illustrator中是一致的。\n例如：UPM=1000，Ascent：852 Descent：-248 ，那我们可以知道该字体大小为  (852+248)/1000 = 1.1 em即当fontSize设置为10pt的时候，他实际大小为11pt。\n如何确定字体宽度\n  宽度和高度基本同理，但宽度的数据在每个字的内部，即Width=glyph.metrics.horizontalAdvance。  width_px = Width / UPM * fontsize_px\n如何确定字体位置\n  确定了字体大小也只是确定了包围盒,但位置并不知道，他以哪个地方为锚点开始画也不知道，这个时候就轮到了baseline这个属性，根据公式Top = (Ascent-baseline)/Height和Bottom = (baseline-Descent)/Height，可以算出baseline所在的位置，bottom_offset = height_px * Bottom，从底部向上偏移bottom_offset这么多就是baseline的位置，字体在设计的时候也是根据baseline进行设计的，这样就确定了位置。\n行高\nUnity\n  TextMeshPro LineHeight=0的时候默认使用的是，TextMeshProAsset中的LineHeigt属性以下称为T_LineHeight，T_LineHeight属性单位和Ascent是一样的，所以计算px的算法也是一致的，lineHeight_px = T_LineHeight / UPM * fontSize_px。LineHeight单位为1em/100，即lineHeight_px = T_LineHeight / UPM * fontSize_px + LineHeight * fontSize / 100\nIllustrator\n  行高就是在位置属性中设置的大小，比如12pt那么一行就是12pt，即换行文字向下偏移12pt。\n文字高度\nIllustrator\n文字高度不同于行高（行高指偏移，文字高度指单行时元素高度），此处文字高度指如下图所示的文字框的高度。\n\n下边界\n在Illustrator中，如下思源黑体之所以出现如此大的高度原因在于其字体内存在glyph，该glyph的ymin比Descent更小，因此导致框的下边界下移，即:  若字体中glyph的ymin小于Descent，则导致下边框下移，要解决这种问题可以尝试将哪些过高的glyph删除。\n上边界\n对于上边框，此处采用 https://www.glyphrstudio.com/app/ 该软件中的数值为基准进行计算，影响上边界的属性为Capital letter height，从baseline到上边界的距离符合h = 0.6*fontSize + 0.5*capital_letter_height/UMP，若文本本身高度超过了该计算值，则该值为文本高度。\n总上所述，文字高度总公式为h = 0.6*fontSize + 0.5*capital_letter_height/UMP - Descent/UPM * fontSize,该公式适用于一般不超过默认边界线的文本，若出现超出的字符则按照相应规则对其中的数值进行替换处理。\n踩坑点\n  在探索上边界规则的时候一开始使用的FontCreator来查看修改的字体数据，但其导出的数据似乎存在兼容性等问题有些字体数据符合预期有些又是不符合预期的，导出的字体在glyphrstudio查看数据发现有些字体与修改的数据不一致，通过在glyphrstudio修改数据后在到Illustrator中进行校验才能算出符合预期的结果。How does Illustrator calculate text frame height 这篇文字中指出OS/2相关的数据，也可能是FontCreator中这部分数据存在问题导致输出字体存在差异。\n在竖版的情况\n  竖版情况下Unity和Illustrator兼容的部分相当有限，这里就记录以下每个部分的渲染逻辑。\nIllustrator\n罗马排布形式\n  罗马排布形式即字母符号不会旋转90度。\n文字高度/行高\n文字大小依赖如下属性:\n\nUPM\nglyphRect\n\n利用UPM来算出字体高度的最小值，glyphRect算出实际高度，例如j会比UMP大一些，a比UMP小，此时得到的高度a为UPM，j为glyphRect算出的高度，换而言之渲染时若字符小于1em则让其占用1em高度，若大于1em，则按实际高度。\n例外，若有字体中有Vertical属性，就以(Vertical_Ascent - Vertical_Descent)为基准。\n非罗马排布\n文字高度/行高\n同罗马排布形式，但区别在于字母和符号，因为会旋转所以长宽需要互换。\n行距\n行距离1000为1em，例如fontSize=12pt，1000即为12pt。\nUnity\n  Unity本质上是没竖版这类型的，可以单字绘制，大小和位置可以通过模仿Illustrator中规则来进行制作。\n其他\nUnity和Illustrator读取的字体属性可能不一致，有时候例如思源黑体，Unity中的字要比Illustrator中大的多，在FontCreator查看可以发现，思源黑体的Typo Ascender和Ascender数值不一样，AI和Unity应该是读取了不同的属性导致两者发生差距，在手动修改Unity的Asset值后，AI与Unity的字体可以一致显示，或者在FontCreator中修改两者的属性值。Illustrator用的Typo Ascender\n工具\n\nhttps://vertical-metrics.netlify.app/\nhttps://www.glyphrstudio.com/app/\n\n参考资料\n\nhttps://paddywang.github.io/demo/list/css/baseline_line-height.html\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Thread模型/","title":"Thread模型","description":null,"body":"  在使用slint构建出应用后导出ffi给C#的Console程序调用时出现了类似Make sure other crates are not using multithreaded COM这样的报错，问题原因如下。\n以下为ChatGPT的答案:\n在C#调用Rust提供的FFI（外部函数接口）时遇到“Make sure other crates are not using multithreaded COM”这样的报错，通常是因为在使用COM（Component Object Model）组件时出现了线程模型不匹配的问题。\n了解COM的线程模型\nCOM有两种主要的线程模型：\n\n单线程单元（STA，Single-Threaded Apartment）：适用于需要单线程访问的COM对象。通常由UI线程使用。\n多线程单元（MTA，Multi-Threaded Apartment）：适用于可以被多个线程安全访问的COM对象。\n\n当在一个应用程序中使用COM时，需要确保所有使用COM的部分遵循同样的线程模型。如果在Rust中某些部分使用了MTA，而C#调用部分期望STA，这会导致线程模型不匹配，从而引发错误。\n解决方案\n\n\n确保线程模型一致：\n\n\n如果C#代码在STA线程中运行，确保Rust代码也在相同的线程模型下工作。\n\n\n可以通过设置C#代码的线程模型来确保一致性：\n\n\n\n\n\nRust中的COM初始化：\n\n\n在Rust代码中使用com库时，需要确保正确设置COM的线程模型。例如，使用CoInitializeEx函数初始化COM库时，指定正确的线程模型：\n\n\n\n\n\n确保无冲突的COM使用：\n\n如果项目中有多个crate在使用COM，确保这些crate之间的COM初始化和使用没有冲突。如果可能，尝试将COM初始化和使用集中在一个crate或一个模块中。\n\n\n\n检查其他可能的原因\n\n引用的第三方库：检查是否有其他引用的第三方库在后台使用了多线程的COM模型。必要时，阅读这些库的文档和源码以了解它们的COM使用方式。\n跨线程COM对象访问：确保没有在STA和MTA之间跨线程访问COM对象的情况。COM对象在不同线程模型之间跨线程访问时，需要进行适当的封送（marshalling）。\n\n总结\n这个错误提示通常是由于C#和Rust代码中的COM使用不一致导致的。通过确保所有部分使用一致的线程模型，并正确初始化COM，可以避免这个问题。如果需要更多详细信息，请提供相关代码片段，以便提供更具体的建议。\n在C#中创建STA线程\n\n经过验证\n可以通过如下几种方式实现Console ffi调用ui\nRust线程启动UI\n通过Rust的thread启动ui线程以正常启动，C#中只需要正常调用ss()即可打开窗口\n\nC#使用STA\n此时rust可以不用写thread相关代码调用ui，通过在CSharp中设置STA即可正常调用ss()\n\n\n","path":null},{"url":"https://yzzfo.github.io/blog/纹理压缩/","title":"纹理压缩","description":null,"body":"在Unity中直接载入png,jpg之类图片的时候对内存的压力是很大的，在Android和IOS可以使用astc格式，win下则可以使用dxt格式格式进行内存压缩，在使用3000x8000图片的时候能将内存从100M降低到10M左右。\nASTC\n从https://github.com/ARM-software/astc-encoder下载相应软件后执行类似./astcenc-avx2.exe -cl ./测试.png test.astc 8x8 -medium -yflip指令即可生成astc图片，-yflip用于翻转图片以适应Unity。\nASTC的前16字节用于描述该图片的信息\n\n通过dim_x和dim_y即可获得图片尺寸(小端字节序)\nwidth = dim_x[0] + (dim_x[1] &lt;&lt; 8) + (dim_x[2] &lt;&lt; 16);\nheight = dim_y[0] + (dim_y[1] &lt;&lt; 8) + (dim_y[2] &lt;&lt; 16);\n在Unity中载入ASTC需要剔除文件头(16字节Loading ASTC texture from file)\n\nDXT\n下载https://github.com/FrozenStormInteractive/Crunch2，通过如下命令crunch -file blah.tga -fileformat dds -dxt1 -mipmode none生成dxt文件\n\n参考\nhttps://discussions.unity.com/t/can-you-load-dds-textures-during-runtime/84192/2\nhttps://stackoverflow.com/questions/25402080/does-endianness-apply-to-bit-order-too\nhttps://huailiang.github.io/blog/2022/astc/\nhttps://forum.unity.com/threads/loading-astc-texture-from-file.945125/\nhttps://dench.flatlib.jp/ddsformat\ndds_texture_loader.c\n","path":null},{"url":"https://yzzfo.github.io/blog/使用Dnsmasq来让host通过名称访问Docker/","title":"使用Dnsmasq来让host通过名称访问Docker","description":null,"body":"  最近在使用Docker的时候遇到了这种问题，首先我想让这个容器能够自由的开放端口供外部访问(例如V2ray的管理面板)，其二我还需要访问其他容器例如(Nginx Proxy)，要完成第一个任务通常使用host模式即可，完成第二件事通常就是创建一个功能的network接口，所有容器都使用这个network接口互相通过域名访问。但现在遇到的需求则是需要同时满足两者的特性，这时候我们可以通过使用Dnsmasq来实现这个。\n思路\n配置Dnsmasq容器jpillora/dnsmasq，让其开放53端口供外部访问，同时使用一个network接口A，其他的容器例如alist,webdav这类希望通过反代访问的容器，也使用network A接口，这样在dnsmasq中我们便能通过容器名称访问到这些容器了，但在默认情况下改容器的/etc/resolv.conf并未配置正常的DNS可以用于解析外部域名例如google.com，所以需要在里面加上一条nameserver 1.1.1.1这样改容器自身便能进行DNS解析了，之后配置Dnsmasq，no-resolv要删除，仅保留server=127.0.0.11这一个server，其他server都删除，这样便配置完成了。\n第二步，设置我们的目标容器为host模式，这样我们便能够自由开放端口，为了通过名称访问其他的容器，我们还需要让本机的dns解析走Dnsmasq去解析，参考设置DNS进行DNS设置，这样我们在宿主机便能通过容器名称访问容器了。\n整体DNS解析流程类似这样\n\nAdguard\n当使用Dnsmasq时若遇到查询不存在的容器名称时会导致出现DNS查询的死循环，其提供的dns-loop-detect使用后又无法查找本地的DNS，在改为使用Adguard后可以解决这个问题，原理和之前的Dnsmasq一样,DNS中添加127.0.0.11(11为Docker内置的DNS),但在设置时需要选择最快的IP地址这个DNS查询选项，只有这个才能保证Adguard在查询时会去调用127.0.0.11,其他两个选择不能确保必定走127.0.0.11进行查询。\nDnsmasq和Adguard组合\n  最近在使用qbittorent的是否发现docker-proxy内存占用过高了，参考这个教程,进行了一下排查发现是adguard导致的，重启几次后发现他的内存占用还是缓慢上升，估计是产生了类似dnsmasq的循环查询导致的，将其改为并发查询后内存有所缓解，但依旧还是维持在比较高的水平，再将127.0.0.11:53给删除之后重启，内存保存在了正常水平，为了解决host模式下解析容器ip的问题最终选择采用adguard+dnsmasq的形式。\n排查时使用的命令\n\nadguard+dnsmasq 结构拓扑\n在宿主机容器中修改resolve.conf或者对特定程序例如nginx在解析时指定127.0.0.2时即可\n\n参考资料\nhow does Docker Embedded DNS resolver work?\n","path":null},{"url":"https://yzzfo.github.io/blog/Blender导出模型到Unity/","title":"Blender导出模型到Unity","description":null,"body":"坐标系\n右手系\n\nBlender中X对应right，-Y对应forward，Z对应up\nObj，X对应right，Y对应up，-Z对应forward\n\nFBX\nFBX SDK中存在几种不同的坐标系，在Blender导出时默认和Obj是一样的坐标系(X对应right，Y对应up，-Z对应forward)\n左手系\n\nUnity中X对应right，Y对应up，z对应forward\n\n导出设置\nObj\n在Blender导出obj时需要将Forward Axis设置为-Z，Up Axis设置为Y，对应Obj格式的要求，这样便会将Blender中的-Y对应到Obj文件中的-Z，Z对应到Obj中的Y。\nFBX\n在Blender导出fbx时需要将Forward Axis设置为-Z，Up Axis设置为Y，对应FBX格式的要求，同时需要Apply Transform，若未Apply Transform则在Unity中会出现绕X选择-90。\n或者使用插件进行导出 https://github.com/EdyJ/blender-to-unity-fbx-exporter\n","path":null},{"url":"https://yzzfo.github.io/blog/OpenGL环境搭建/","title":"OpenGL环境搭建","description":null,"body":"开发环境\n\nWin11\nVisual Studio 2022\nHelix\n\n环境搭建\n安装\n\n下载cmake并加入环境变量中\n安装LLVM，用于获得clangd使得helix中的支持cpp代码提示\n\n项目配置\n\n\n下载glfw和glew，解压至third文件夹中\n编写CMakeLists.txt文件\n\n\n\nCMake\n此时使用Ninja来生成项目(为了生成compile_commands.json，visual studio生成器不支持生成该json文件)，为了生成正确的配置需要执行vcvars64.bat来配置环境编辑，这样生成的配置文件才会正确引用visual studio工具链作为编译工具。\n\nHello World\n\n\n\nCompile\n由于使用Visual Studio工具链，所以需要先设置vs环境变量，运行vcvars64.bat即可\n\n\n\n其他\n也可以通过其他方式替代执行vcvars64.bat，即通过使用Develop Command Prompt for VS 2022这个终端，在这个终端中关于vs的环境变量全部都已经加载好了，直接使用即可。\n\n配置Helix\n新建.helix文件夹，作用类似于.vscoed文件夹\n配置LSP\n覆盖默认cpp的lsp配置，其中--limit-results=0用于禁用返回结果的数量限制(因为GL开头的元素很多，导致超出了最大数量限制，进而导致代码提示不全)。  --fallback-style=Microsoft用于配置代码格式化为Microsoft的规则。\n\n配置Config\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Unity中的颜色空间/","title":"Unity中的颜色空间","description":null,"body":"颜色空间\nGamma\n  由于人眼对于暗色的变化更为敏感，所以在精度有限的情况下会分配更多的有效值用于描述暗部，于是引申出了Gamma颜色空间。通过 y=x^0.45 在x = 0-1范围内，将暗部值精度提升，本质上是对图片进行增亮操作。通常显示器在显示时会进行Gamma解码操作，即y=x^2.2 本质是进行 变暗 操作。\n\nLinear\n线性空间就是Gamma值为 1 的情况，也就没所谓的编码解码的必要了。\nPNG\n  对于PNG这种文件来说，并不关心Gamma或者Linear，他只管保存颜色的数据，至于该颜色数据读取后是该Gamma校正还是直接使用由使用者来决定。\n\n对于颜色(0.5,0.5,0.5)，若使用Gamma编码则其在PNG中的值为(0.73,0.73,0.73)，若使用Linear则依然是(0.5,0.5,0.5)\n在PNG的元数据中可以查看Gamma值，但该值并不是必须保存的，所以在没有Gamma值时并不能判断该图片是否进行过Gamma编码\n\nsRGB\n1996年，微软和惠普一起开发了一种标准sRGB色彩空间。这种标准得到许多业界厂商的支持。sRGB对应的是Gamma0.45所在的空间\nUnity中的颜色空间\nLinear\n\n在Linear Space下，图片导入时若勾选sRGB，则在Shader中使用该图片时会自动进行Gamma校正，即对图片进行变暗操作，使颜色值回归线性，即 (0.73,0.73,0.73) =&gt; (0.5,0.5,0.5)\nShader输出颜色时，Unity会自动进行Gamma编码，即假设当前frag输出(0.5,0.5,0.5)，此时若将其保存到Texture时可以发现存储的值为(0.73,0.73,0.73)，即在Linear Space下，Unity输出的图片为sRGB。\n\nGamma\n\n在Gamma Space下sRGB选项将不会生效，将会按照实际值传入Shader中，若要解码则需要自己在Shader中进行相应操作。\nShader输出时并不会自动转换为sRGB，即frag输出(0.5,0.5,0.5)，Texture中存储的也为(0.5,0.5,0.5)。\n\n\nTexture Setting\n\nAlpha is Transparency\n\n如果指定的 Alpha 通道为透明度 (Transparency)，则启用此属性可扩充颜色并避免边缘上的过滤瑕疵。\n由于勾选后可能会改变图片原本的RGB，所以需要更具情况选择是否启动。\n\n\nFormat\n\n对于Texture的不同设置可以通过断点来具体看看不同设置对应的属性\nhttps://docs.unity3d.com/ScriptReference/Experimental.Rendering.GraphicsFormat.html\n例如RGB16其graphicsFormat: B5G6R5_UNormPack16 ，所以他并不支持sRGB选项，若要正常使用则需要切换格式或者在Shader中手动解码\n\n\n\nColor Property\n在Shader中，Color属性是以sRGB模式传递的，所以在Linear空间下他会自动De-Gamma,SL-PropertiesInPrograms\n\n\n例子\n导入的层级图失效\n\n层级图 每一层对应的R=index x 0.1 G=0.5\nshader中根据G&gt;=0.49，Ceil(R x 10)来判断是否属于层级，以及获取层级\n失败的原因在于，用于导出层级图的Unity项目使用的Gamma Space，而主工程使用的是Linear，new Texture时默认为sRGB，导致图片整体变暗，所以G&gt;=0.49判断条件已然不满足，且后续层级获取也将出现问题，正确方法是new Texture时将linear参数设置为true。\n设置为RGB16时图片变正常了？\n因为在Unity中RGB16不支持sRGB选项，所以使用时自动采用了PNG中的值输入到Shader中，所以正常了。\n\n图片\n\n\n\n\n参考\n\nGamma、Linear、sRGB 和Unity Color Space，你真懂了吗？\nGamma空间和Linear空间 全解析\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Unity笔记/","title":"Unity笔记","description":null,"body":"遇到的一些问题\n\n某些 Unity 内置错误或者 Exception 不显示 Log\n从 Console window menu 中修改 Stack Trace Logging 中的相关内容即可\n在使用 Build Tool 构建 Android 包的时候出现 Graphic api 不支持相关的报错，发现是 Build 配置中 Texture Comporession 设置为了 Generic 导致的。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Unity包体大小优化/","title":"Unity包体大小优化","description":null,"body":"重复资源\n何时出现重复资源\n在 Unity 中 AB 包和项目本地资源需要当成两个环境来看待，即当 AB 包中引用到了本地资源则每个引用到的 AB 包都会 Copy 一份该资源到自己的包内，例如在 Resouces 文件中存在一个图集 A，以及他的图源 A1，A2，A3，若存在 AB1，AB2 这两个 AB 包分别引用了 A1 和 A2，则资源（图集 A，以及他的图源 A1，A2，A3）将会在 AB1 和 AB2 中都存在一份，这样将导致整个项目中共有（图集 A，以及他的图源 A1，A2，A3）的三个副本。反之一样，若 Resouces 中引用到了 AB 中的资源，则会 Copy 一份到本地。\n解决方法\n解决方法便是对 AB 资源以及本地资源做严格的划分，禁止在制作资源阶段便相互引用。\n如何确认问题，以及查找源头\n在 Unity Build 之后会产生 Editor 日志 (Open Editor Log&nbsp;from the Console window menu)，可以通过日志来确认有什么资源打到了本地之中，在确认到属于 AB 资源相关的路径时，可以在 Editor 下通过类似Maintainer的插件来查找该资源的引用，从而确认问题源头，日志内容类似如下片段。\n\n也可以通过 AssetStudio 来解包，来看看里面具体存在什么资源，从而判断是否出现重复资源。\n对于 AB 资源则可以通过一些插件来进行搜索，对于 Addressable 来说在 2022 版本有 Report 窗口可以看到具体资源打包的情况用于处理重复问题。\n资源导入\n字体\n通常字体文件都比较大，许多人采用字体压缩的方式比如使用 FontZip 来提取出想要的字体来缩减字体大小，然后在 Unity 中使用动态字体，其实在某些场景下也可以使用 Unity 的静态字体，选中字体文件设置 Character 选项为非Dynamic的即可，这么做同样能够减小打包时字体的体积，对于某些场景只需要设置常用的汉字到静态集合中就够了。\n字体在项目中自动引用问题\n有时会发现字体文件自动引用到了项目中另一个字体，即便他们名字并不同，这是因为他们的字体文件中的字体名称是相同的导致相互关联了起来，可以通过修改字体文件来解决，或者直接修改 meta 文件，将关联项删除即可。\n\n参考： https://blog.uwa4d.com/archives/2249.html\n音频和图片\n对于音频主要可以修改一下 Force To Mono，可以将双声道修改为单声道，大幅节省内存，音频和图片主要还是具体看美术效果，在几乎不影响美术效果的情况下可以尽可能的降低质量设置，例如某些地面贴图可以直接改为 32 其效果和 2048 甚至没什么效果上的差异。\n","path":null},{"url":"https://yzzfo.github.io/blog/修改Editor/","title":"修改Editor","description":null,"body":"   最近在制作技能的时候感觉到 Unity 内建的资源选择工具在选择自建类型的资源时十分的难受，所以尝试来修改一下 Unity 的编辑器。\n整体方案参考 Ultimate Editor Enhancer 这个插件，其修改内建元素时采用的是 Harmony 这个插件，其原理与在雨中冒险mod制作 一文中的 BepInEx 差不多，都是通过 Hook 的方式进行修改。\n修改ObjectField\n入口\nObjectField 的绘制入口是 EditorGUI 下的 DoObjectField 函数，他已经在 ObjectFieldInterceptor 类中被 Hook 了，可以在 Prefix 中劫持点击事件，并打开自己对于的选择界面。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/NodeCanvas/","title":"NodeCanvas","description":null,"body":"   最近弄技能系统的时候又重新拿出了 NodeCanvas，故在这边记录一些 NodeCanvas 相关的东西。\n关于 NC 编辑器代码相关的内容\nAttribute 的绘制逻辑\n以 RequireField 为例，可以发现调用和实际逻辑时通过泛型 AttributeDrawer&lt;RequiredFieldAttribute&gt; 来关联的\n\n\nBBParam\n该类型的 Editor 脚本在 ParadoxNotion\\CanvasCore\\Framework\\Design\\PartialEditor\\Drawers 下，其 object 选择区域也用的时 unity 内置的objectfield\n","path":null},{"url":"https://yzzfo.github.io/blog/UGUI笔记/","title":"UGUI笔记","description":null,"body":"合批操作\n\n\n添加图集\n\n\n设计 Prefab 时尽量保持层级一直，如下图。在该图中通过 SelectEffect 的 active 控制选择特效，这样将会导致该 Prefab 自 SelectEffect 起后续节点的层级将与其他的该 Prefab 实例不一致，从而导致合批失败，正确做法是将 SelectEffect 移到最后一个，这样便可保证前面的元素层级保证一致。\n\n\n\n注意元素大小，如下图。一个 Img 和 Text 不重叠，一个 Img 和 Text 重叠，这也导致层级发生改变，进而导致 Text 无法合批。\n\n\n\n总的来说，在 UGUI 合批时可以依照如下方式判断。\n如果有三个实例化对象，InsA, InsB, InsC，若 Backgroud 和 ContentImg 在同一个图集中，则这六个元素将使用一个 drawcall，对于 Text，若重叠方式都相同，也一个 drawcall，若不同则根据有几种不同的重叠层级确定 drawcall。\n\n\nInsAInsBInsC\nBackgroudBackgroudBackgroud\nContentImgContentImgContentImg\nTextTextText\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Addressable笔记/","title":"Addressable笔记","description":null,"body":"增量更新\n配置\n\n\n修改Addressable Asset Settings中的Catalog，使其支持服务端清单，Only update catalogs manually 选项用于禁止自带的自动更新功能。\n\n\n\n为资源组设置远程模式，其中Use Asset Bundle Cache用于标记该bundle下载后会缓存到设备上，Prevent Updates勾选后则意为该资源为静态资源，对该组的修改后续将进行增量更新，反之为全量更新。\n\n\n\n配置服务器地址，其中RemoteLoadPath对应bundle所在的文件夹，修改Play Mode Script为Use Existing Build用以使用真实环境测试。\n\n\n\n\n打包\n\nBuild第一个包\n\n修改了某个Group中的资源后，进行增量更新，这里只有勾选了Prevent Updates组中的物体才会出现，填入一个新的Group名即增量包名，点击Apply即会创建出一个新的组，之后选择更新新包即可打出新的资源。\n\n\n\n\n代码\n\n测试\n\n在Play Mode Script为Use Existing Build时Editor下也是存在Bundle缓存的，所以也是可以测试更新逻辑的。\n可以通过Unity自带的Web服务来搭建本地文件服务，可以在Play Mode Script为Use Existing Build起作用。\n\n在 Simulate Groups 模式下需要使用如下代码来修改速度，一下设置虽然说是 ProjectConfigData，但没有在 Project 相关配置中找到，只在 Library\\com.unity.addressables\\catalog.json 这个文件中搜索到了相关配置，所以在设置后第一次运行不生效，需要重新生成 catalog.json 才会生效。\n\n\n\n要启用 Event Viewer 需要开启如下选项\n\n\nAddressables.MergeMode\n\nCatalogs\n\n当关闭Only update catalogs manually时Addressables.InitializeAsync();会更新Catalogs文件\n手动调用Addressables.UpdateCatalogs()相当于关闭Only update catalogs manually`干的事\n当勾选Only update catalogs manually时，直接调用Addressables.CheckForCatalogUpdates(false);时Result将包含所有内容。\n更新检查仅是对比Catalogs文件，所以当CheckForCatalogUpdates后去下载对应的文件中途断开后，重新进入CheckForCatalogUpdates将无法获取到新的内容，因为本地Catalogs文件已经为最新的了。\n如果中途断开，若之后用到了被更新的文件，Addressables将去获取新的文件。\n\n\n资源载入\n在Addressable中有两种加载方式，一种是LoadAssetAsync另一种是InstantiateAsync，他们的区别在于，LoadAssetAsync后必须Release否则引用计数会一直存在，InstantiateAsync则是当切换场景时，若实例化的对象被销毁了对应的引用计数也会消失。\n在Addressable类这个层，LoadAssetAsync和InstantiateAsync均可以使用Release进行销毁，ReleaseInstance仅添加了实例判空检测。\n之所以InstantiateAsync在切换场景是会判断引用计数是可以参考Library/PackageCache/com.unity.addressables@1.21.9/Runtime/ResourceManager/ResourceProviders/InstanceProvider.cs可以看到对于实例化物体都有一个字典将其记录了。\nRelease注意点\n\n注意点\n\nNon-Recursive Dependency Calculation：开启该选项可以提高构建速度同时减少运行内存的占用，但资源存在循环依赖时会导致加载失败。不建议开启。\n场景切换时死锁问题\n切换平台后, Editor 下读取路径出现问题，解决方法是清除一下缓存。\n切换 Android 后出现 TLS 错误，在开发模式下 Edit -&gt; Project Settings -&gt; Player -&gt; Other Settings -&gt; Configuration -&gt; Allow downloads over HTTP 可以在这设置一下。\n读取 Built in date 中的文件时文件Key 没有后置名，同 Resource. Load 一样不需要文件后缀名，截至 1.21 版本在 Group 界面下复制 Resources 文件夹下的 Key 时还是会多出后缀名，去除后缀名才是真正的 Key。具体参考 ResourceLocationMap.cs 文件中的 Locate 函数，在此处断点可看到具体的 Key 值。\n\n缓存位置\n项目名 : com.DefaultCompany.Addressables\nPC/Editor :  C:\\Users\\\\AppData\\LocalLow\\Unity\\DefaultCompany_Addressables\n安卓 :InternalSharedStorage&gt;Android&gt;data&gt;com.DefaultCompany.Addressables&gt;cache&gt;vulkan_pso_cache.bin\n关联文章\n\n场景相关内容\n\n参考资料\n\nAddressables之使用 截图存档\nhttps://zhuanlan.zhihu.com/p/243606717\nhttps://www.jianshu.com/p/dfa98f540673\nhttps://medium.com/swlh/need-a-local-static-server-here-are-several-options-bbbe77e59a11\nhttps://www.bilibili.com/read/cv11642315\nhttps://answer.uwa4d.com/question/62a18c85b87a457351737513\nhttps://www.cnblogs.com/qq2351194611/p/16601170.html\nhttps://docs.unity3d.com/Packages/com.unity.addressables@1.20/manual/SynchronousAddressables.html\n\n","path":null},{"url":"https://yzzfo.github.io/blog/使用Addressables加载场景/","title":"使用Addressables加载场景","description":null,"body":"在Unity中可以通过如下方式加载场景\n\n但这两种方式均存在问题，如下\n\n异步加同步加载时Update报错\n\n\n\n\n场景的Active存在延迟\n\n\n\n对于这两个问题其实都是由于Unity资源加载异步实现方式导致的，在Unity中资源加载完成后的回调是通过在Update中轮询完成的，即资源即便已经加载好了，这个时间也需要到下一次的Update中去派发事件。\n所以可以采用UniTask中的await UniTask.Yield(PlayerLoopTiming.LastUpdate);在资源加载结束后使用该函数将任务移到Update的结尾处，这样便能确保ActivateAsync已经结束了，而且也可以跳出Update的报错。\n\n显示进度\n\n注意点\n场景切换卡死\n\n切换场景时场景中存在同步加载的资源时导致卡死，原因如下\n\n\n\n虽然文档说是因为 Scene 切换时不能同步是因为切换时会 UnloadUnusedAssets，但经过实验发现调用 Resources.UnloadUnusedAssets() 后立马去同步 Load 资源也不会卡死，应该是 Scene 切换时还有其他的操作导致 Lock 住了其他的资源加载。可以参考 Addressables AssetLoading is blocked by Async Scene Loading\n卡死问题复现的代码\n\n\n\n解决方式是，若要使用同步加载需要预加载资源\n\n\n\n还遇到过在切换场景后的 1-2 帧内 LoadAsync 某个特定资源是 Editor 卡死且 CPU 占用率为 0，且无法断点定位。\n后发现可以等待几帧在去加载资源。\n通过在 Groups 面板中删除资源，重新拖回去之后重新 Build 资源彻底解决了部分该问题，但至于为什么出现这个情况未知。\n最终解决方方法还是需要等到场景彻底加载完之后再去请求资源加载才不会卡死，即 await ret.ActivateAsync(); 和同步加载时的策略一样。\n\nUnity中的时序\n\n参考资料\nUnity 2018 and PlayerLoop\nAddressables之使用\n","path":null},{"url":"https://yzzfo.github.io/blog/Tilemap/","title":"Tilemap","description":null,"body":"Isometric\n设置渲染轴\n\n在SRP下Edit &gt; Project Settings &gt; Graphics 设置Transparency Sort Axis 为 (0, 1, 0)\n\n在URP下需要进行如下设置\nCreate &gt; Rendering &gt; URP Asset (with 2D Renderer)创建2D渲染器\n在Project Settings &gt; Graphics中使用2D的渲染管线\n查看相机Rendering &gt; Renderer属性中是否选择到了目标文件，若没有则到Project Settings &gt; Quality中查看当前是否有旧的Render Pipeline Asset设置残留，比如用URP 3D 模板创建的项目会更预先生成几份不同画质的配置在此处设置，会导致第二步中的配置被该处覆盖，可根据项目质量自行在该出修改。\n在Renderer2D文件中修改轴\n\n设置图片资源以及网格比例\n\n如上图所示，在Isometric中，一个物体本质是由一个基础的面从上自下刷出来的，计算比例时便是拿这个基础的面，在这个图片中其比例为(128 : 66) =&gt; (1 : 0.515)\n设置CellSize\n在Grid组件上，Size采用Unity空间下的长度为单位，若要将上图的映射到一个格子内，则Size需要满足比例(1 : 0.515)才能保证平铺，此处以(2 : 1.03)为例子\n设置图片所对应的Unit大小\n为了铺满(2 : 1.03)则Pixels Per Unit设置为128/2=64，使得在该图片中每128px对应Unity空间中的长度2即可。\n关于Pattern\nPattern只不过是一个预制体+Editor，当创建完后想修改基本参数如Cell Layout则可以到预制体中修改，Pattern中设置并不会影响到实际场景中，显示仅作为在该种布局下的预览而已，例如在Pattern中设置Layout为Rectangle但是场景中是Isometric也并不影响。\n一些笔记\n计算坐标\n\n","path":null},{"url":"https://yzzfo.github.io/blog/UI-ToolKit/","title":"UI ToolKit","description":null,"body":"  Unity在2019之后就可以使用UI ToolKit来制作，其制作理念和web前端基本一致，所有这里记录一下相关的内容。\n基本结构\n通过Create &gt; UI Toolkit &gt; Editor Window即可创建一个最基本的Editor窗口\n\n监听UI事件\n\nListView\n\n拖拽相关内容\n修改鼠标样式\n  在反编译查看了下ObjectField后发现了DragAndDrop.visualMode = DragAndDropVisualMode.Generic这一行代码，试了一下后发现可以用于修改拖拽时的鼠标样式\n\n获取拖拽的物品\n  可以通过DragAndDrop或者Selection下的属性来获取相关内容\n\n修改Sprite\n修改资源时需要修改对应的Importer，AssetImporter.GetAtPath，有些修改项不在import中需要使用对应的ImporterSettings，如下面例子。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Unity-Mesh/","title":"Unity Mesh","description":null,"body":"SharedMesh和Mesh的区别\nsharedMesh是指MeshFilter组件中共享的mesh，它会影响所有使用这个mesh的对象。如果你想修改一个对象的mesh而不影响其他对象，你可以使用MeshFilter组件中的mesh属性，它会返回一个新的mesh副本。\nSubmesh和Materials\nSubmesh 是指一个 mesh 中的一部分，可以用来给不同的部分应用不同的材质。对应到 Blender 中则是一个 object 中存在多个分开的网格，如下图 mesh 中存在两个 submesh(材质不同的时候两个，相同的话一个)。\n\nSubmesh和Materials对应的关系为\n\n若Submesh数量等于Material数量，则index对应赋值\n若Submesh小于Material数量，相等部分对应赋值，多出的Materials重复作用于最后的Submesh上\n若Submesh大于Material，相等部分对应赋值，剩下的Submesh都使用最后的一个Material\n\nCombineMesh\nCombineMesh有一个参数叫mergeSubMeshes，它可以控制合并后的mesh是否只有一个submesh。如果你设置为true，所有的submesh都会合并成一个submesh。如果你设置为false，每个submesh都会保留在不同的submesh中即需要一个drawcall。\n\nCombineMesh的好处\n当mergeSubMeshes为false的时候，可以看出来他的drawcall并没有降低，对于类似换装系统这样的功能来说倒是可以将多个SkinmeshRender变成一个SkinmeshRender，可能从结果上来看可以减少一些渲染状态切换之类的东西，例如每次渲染Unity都需要设置一些渲染参数，比如材质、光照、混合模式等。如果你把多个mesh合并成一个mesh，你就可以减少这些参数的设置次数，从而提高效率。\n\nTriangle\n在存储顶点以及确定它们的三角面时通常会有如下几种方法:\n\n\n三角形条带法：这是一种绘制三维图形的方法，它可以减少顶点数据的冗余，提高渲染效率。它的原理是，按照一定的顺序指定一系列顶点，然后每相邻的三个顶点构成一个三角形。例如，如果指定了7个顶点v1,v2,v3,v4,v5,v6,v7，则会绘制出4个三角形：v1v2v3, v2v3v4, v3v4v5, v4v5v6。\n\n\n三角形扇法：这也是一种绘制三维图形的方法，它可以用较少的顶点数据来表示圆锥或球体等曲面。它的原理是，以一个顶点为中心，与其他顶点依次构成一系列扇形的三角形。例如，如果指定了6个顶点v1,v2,v3,v4,v5,v6，则会绘制出5个三角形：v1v2v3, v1v3v4, v1v4v5, v1v5v6, v1v6v2。\n\n\n四边形条带法：这是一种绘制四边形网格的方法，它可以用两条线把一系列四边形交错起来。它的原理是，按照一定的顺序指定一系列顶点，然后每相邻的四个顶点构成一个四边形。例如，如果指定了8个顶点 v1,v2,v3,v4,v5,v6,v7,v8，则会绘制出3个四边形：\n\n\nv1-v2-v4-v3\n\n\nv3-v4-v6-v5\n\n\nv5-v6-v8-v7\n\n\n索引缓冲法：这是一种优化渲染性能和内存使用的方法，它可以避免重复存储相同的顶点数据。它的原理是，使用一个数组来存储所有不重复的顶点数据（称为顶点缓冲），然后使用另一个数组来存储每个图元（如三角形或四边形）所需的顶点索引（称为索引缓冲）。例如，如果要绘制一个立方体，则只需要8个不同的顶点和36个索引。\n\n\n在Unity在Meshfileter的triangles属性就是使用的索引缓冲法。对于不同的存储方法，在OpenGL中也是有对应不同的绘制方法，有些图元类型是每三个点认为一个三角的索引缓冲法，比如GL_TRIANGLES，有些图元类型是用的三角形条带法，比如GL_TRIANGLE_STRIP。\n三角形条带法的一些劣势\n人物的网格通常是非常复杂和不规则的，很难用一系列连接的三角形来表示。如果要用三角形条带法来绘制人物，就需要分割成很多小的条带，并且使用很多退化的三角形来连接它们，这样就会降低效率和质量。\n三角形条带法有可能无法画特点拓扑的模型，它只能用一系列连接的三角形来表示网格，而不能自由地指定任意顶点之间的连接关系。\n这样就会导致一些问题，例如：\n\n三角形条带法不能绘制具有洞或凹陷的模型，因为这些模型需要断开或跳过一些顶点。\n三角形条带法不能绘制具有复杂曲面或细节的模型，因为这些模型需要更多或更少的顶点来控制曲率或密度。\n\n如果模型需要在某些地方有很高的法曲率，就需要增加顶点来使三角形条带能够适应这种弯曲变化。\n如果模型需要在某些地方有很低的法曲率，就需要减少顶点来使三角形条带能够保持平滑和均匀。\n但是三角形条带法只能用顺序的顶点来表示网格，不能根据不同位置和方向调整顶点数量和位置。\n\n\n三角形条带法不能绘制具有动画或变形的模型，因为这些模型需要更好的拓扑结构来保持平滑和连贯。\n三角形条带法的定义是：一系列连接的三角形，其中每个新顶点与前两个顶点共享一条边。三角形条带法的实现是：使用一个数组或缓冲区来存储顶点数据，然后按照固定的规则来遍历这些顶点并绘制三角形。因此，如果要改变顶点数量或位置，就需要重新创建或修改数组或缓冲区，并重新遍历和绘制所有顶点和三角形。这样就会增加计算和内存开销，并降低渲染效率。\n\n索引缓冲法则可以更灵活地指定任意顶点之间的连接关系，从而可以绘制任何形状的网格，包括人物。\n","path":null},{"url":"https://yzzfo.github.io/blog/Unity-Shader-Depth/","title":"Unity Shader Depth","description":null,"body":"在之前学习Shader时一直有一个误解，认为SV_POSITION在Frag阶段依旧是裁剪坐标系，于是在手动计算深度缓存时出现了一些问题，原因在此。\n通常来说在NDC空间下z值(-1,1)映射到depth = 0.5*ndcz+0.5，即ZBuffer中的值。在Frag阶段只需通过SV_POSITION即可获取当前像素所在的depth值。\n\n\n也可以通过Unity提供的API在Vertex阶段来计算深度\nUnityCG.cginc\n\n\n在顶点阶段调用上面的任意函数获取深度值，之后到片元着色器去使用，在片元着色器通过如下函数对_CameraDepthTexture中的值解码\n\n使用案例\nVertex\n通过顶点计算深度值\n\nFrag\n获取当前ZBuffer中的值的方式\n_CameraDepthTexture\n\n\n\n这样，相机就会生成深度纹理，并且你可以在Shader中访问它。如果是延迟渲染，则不需要手动设置，因为相机默认就会生成深度纹理。\n\n\n\nNote\n_CameraDepthTexture生成的Depth是通过\"LightMode\" = \"ShadowCaster\"的Pass来渲染出来的，在Surface Shader中通常只需要加入addshadow即可，若Shader中两者都不存在，若Fallback中的Shader有ShadowCaster也会渲染出Depth。\n\n也存在一种不需要任何设置就能获取的全局属性_LastCameraDepthTexture即上一次的深度信息，使用方式同上。\n\n_CameraDepthNormalsTexture\n\n\n\n\n\n\n通过该模式，你可以在Shader中访问到Depth以及Normal信息\n\n\n\nNote\n_CameraDepthNormalsTexture使用的ShaderReplacement进行生成，ShaderReplacement通过匹配RenderType进行替换操作，默认使用Internal-DepthNormalsTexture.shader进行替换操作，若要更改需要在Unity中进行相关设置，如下图。\n\n\n\n一些疑问\n\n在Unity中为什么NDC空间下Z值越近越大？\n在Unity中，NDC空间下的z值从大到小是因为Unity使用了反向z(Reversed-Z)来处理z fighting问题。反向z先是把摄像机的矩阵改了，然后自动把你的shader的ztest creater和ztest less翻转，深度测试本身就没问题了。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Shader-Pass/","title":"Shader Pass","description":null,"body":"Tag是一种用来给SubShader或Pass添加一些额外信息的语法，可以影响渲染的顺序、方式和效果。\nUnity Shader里的Tag分为两种，一种是子着色器（SubShader）Tags，一种是通道（Pass）Tags。\n子着色器Tags可以设置以下几种：\n\nQueue：表示渲染队列，决定了物体的渲染顺序。\nRenderType：表示渲染类型，用于后处理效果和替换渲染等功能。\nDisableBatching：表示是否禁用批处理，用于优化性能。\nForceNoShadowCasting：表示是否强制不产生阴影，用于优化性能。\nIgnoreProjector：表示是否忽略投影器的影响，用于优化性能。\nCanUseSpriteAtlas：表示是否可以使用精灵图集，用于优化性能。\n\n通道Tags可以设置以下几种：\n\nLightMode：表示光照模式，决定了这个pass在何种光照下被激活。\nName：表示pass的名字，用于调试和识别。\nRequireOptions：表示需要满足的条件才能激活这个pass，例如需要开启雾效或者HDR等。\n\nSubshader中拥有多个相同的RenderType时\n\n如果你的一个shader中有好几个相同rendertype的subshader，那么只有第一个能够运行在用户的显卡上的subshader会被渲染，其他的subshader会被忽略。\nUnity会根据用户的显卡性能和设置来选择最合适的subshader，所以不同的subshader应该提供不同的渲染效果和质量。\n如果你想要在一个shader中实现多种渲染类型，你可以使用多个pass来实现，而不是多个subshader。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Shadow/","title":"Shadow","description":null,"body":"Unity的shader实现阴影的方法有多种，其中一种是使用Shadow Map技术。Shadow Map是一种记录光源视角下场景深度信息的纹理，可以用来判断物体是否在阴影区域。\n\n如果想要渲染的物体接收阴影，就要在Shader中对阴影映射纹理进行采样，通过采样结果和光照结果相乘来产生阴影效果。Unity提供了一些内置的宏和函数来方便这个过程，例如SHADOW_COORDS, TRANSFER_SHADOW, SHADOW_ATTENUATION等。\n如果想要渲染的物体产生阴影，就要在Shader中添加一个ShadowCaster Pass，用来告诉Unity如何生成Shadow Map。Unity也提供了一些内置的宏和函数来简化这个过程，例如SHADOW_CASTER_FRAGMENT等。\n在普通Shader中实现接收Shadow\n\n相关宏的定义\n\nTRANSFER_SHADOW\n将顶点坐标转换到阴影视锥的空间中\nSHADOW_ATTENUATION\n采样\n阴影投射\n在普通Shader中实现阴影投射\n\n在Surface Shader中实现\n在默认的模板情况下，我们直接使用alphatest剔除像素后，该物体所投射的阴影依旧是完整的，这时需要在optionalparams加入addshadow指令\n除了Shadow Map之外，还有其他的实现阴影的方法，例如Screen Space Shadow Map、Shadow Matte Shader、Unlit Shader with Shadow Caster Pass等。\n","path":null},{"url":"https://yzzfo.github.io/blog/Surface-Shader/","title":"Surface Shader","description":null,"body":"  Surface Shader是Unity进行抽象过的一层Shader，有时候想基于Unity默认Shader的基础上加一些特效时使用Suface Shader在合适不过了，创建默认的Surf Shader时便以及实现了PBR相关的功能。\n使用方法\n编译指令\n# pragma surface surfaceFunction lightModel [optionalparams]\n类似透明度测试之类的东西需要在optionalparams处声明\nInput\n只能使用Unity提供的相关变量，诸如worldPos，screenPos等\n顶点动画\n在optionalparams中加入vertex:VertexFunction，并编写对应函数即可\n\n阴影\n在默认的模板情况下，我们直接使用alphatest剔除像素后，该物体所投射的阴影依旧是完整的，这时需要在optionalparams加入addshadow指令\n一个Dissovle的例子\n\n参考资料\n编写表面着色器 - Unity 手册 (unity3d.com)\nSurface Shader examples\n","path":null},{"url":"https://yzzfo.github.io/blog/Shader中的分支/","title":"Shader中的分支","description":null,"body":"  在学习Shader时经常会看到这么一条注意事项少用if else语句，通常的原因是在着色器中使用条件语句（如if）可能会影响效率，因为它们会破坏着色器的并行性。如果你想根据某个值的大小来选择不同的输出，你可以使用step函数，它会返回0或1，然后你可以用它来做插值或混合。step函数比if语句更高效，因为它没有分支。\n为什么Step比 If 快\nstep函数的实现可能会根据不同的平台和语言有所差异，但是一种常见的实现方法是使用比较运算符和逻辑运算符。例如，如果你想实现一个返回0或1的step函数，你可以这样写：\n\n这里的?是一个三元运算符，它相当于一个简单的if-else语句，但是它不会产生分支。你可以把它理解为：\n\n但是这种写法就会有分支，因为它会根据条件选择不同的返回值。而三元运算符只是一个表达式，它会同时计算两个可能的返回值，然后根据条件选择其中一个作为结果。这样就避免了分支。\n三目运算符为什么没有分支，这个问题的答案可能会取决于编译器和CPU的具体实现。一种可能的解释是，三目运算符是一个表达式，它可以被优化为一个单一的指令，而不需要跳转或分支。另一种可能的解释是，三目运算符可以让CPU更容易预测条件的结果，从而减少分支预测错误的代价。无论哪种情况，三目运算符都比if语句更高效，因为它避免了不必要的分支。\n一些写法\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Shader-Semantics/","title":"Shader Semantics","description":null,"body":"  在学习Shader是经常会看到诸如TEXCOORD0,POSITION,这样的东西，这些东西叫做Semantics中文叫做语义。\n作用\n在Unity的shader中，TEXCOORD0，POSITION等都是用来表示顶点和片元的数据的语义。语义是用来指示HLSL shader程序中输入和输出变量的意图的。\n例如，POSITION语义表示顶点在裁剪空间中的位置，以便GPU知道屏幕上的光栅化位置和深度。&nbsp;TEXCOORD0，TEXCOORD1等语义用于表示任意高精度数据，如纹理坐标和位置。&nbsp;顶点输出和片元输入的COLOR0和COLOR1语义用于表示低精度0到1范围的数据（如简单的颜色值）。\n语义的规则或限制\n\n语义必须是从以下列表中选择的：POSITION，NORMAL，TANGENT，TEXCOORD0-7，COLOR0-1，SV_Target等。\n语义必须与变量的类型和维度匹配。例如，POSITION必须是float3或float4，COLOR0必须是float[2|3|4]等。\n语义不能重复使用。例如，不能有两个变量都使用TEXCOORD0语义。\n片元shader的输出语义通常是SV_Target，表示输出的颜色值。\n\n可以参考MSDN上的Semantics文档来了解更多细节。\n为什么要使用语义\n使用这些语义的原因是，它们可以传递关于参数的预期用途的信息，从而使shader程序与GPU和其他shader阶段之间的通信更加清晰和有效。\n例如，POSITION语义告诉GPU这个变量是用来表示顶点位置的，而TEXCOORD0语义告诉GPU这个变量是用来表示纹理坐标的。这样，GPU就可以根据语义来正确地处理和插值数据，并将其传递给下一个shader阶段（如片元shader）。\n可以把语义看作是一种约定或标签，它们帮助组织和管理shader代码，并避免一些错误或混乱。\n系统语义\n为什么MSDN上TEXCOORD0为float4，使用时却可以声明为float2，但在规则或限制中却说了类型必须匹配？\n\n之前说的POSITION必须是float3或float4类型，是指在顶点shader输出或片元shader输入时，使用的SV_POSITION语义，这个语义是用来表示顶点在裁剪空间或屏幕空间的位置的，它是GPU栅格化和深度测试所必需的\n由于裁剪空间和屏幕空间都是三维或四维的，所以SV_POSITION语义必须使用float3或float4类型来声明。&nbsp;如果使用其他类型，例如float2，那么GPU将无法正确地计算顶点的位置和深度，从而导致渲染错误。\nCOLOR也同理，指的shader片元输出时的SV_Target语义。\n根据MSDN中所述DX10的SV_Target等效DX9的COLOR,所以在Unity中会看到一些宏定义将SV_Target定为COLOR\n而TEXCOORD0语义则不同，它只是用来表示纹理坐标或其他任意数据的，并不影响GPU栅格化和深度测试。&nbsp;因此，TEXCOORD0语义可以使用任何合适的类型来声明，只要与其他shader阶段之间的数据传递保持一致即可。\n他们之间的差别就在于SV_POSITION语义是一个特殊的系统值语义（System-Value Semantics），它有一些固定的规则和约束，而TEXCOORD0语义则是一个普通的用户定义语义（User-Defined Semantics），它有更多的灵活性和自由度。\n\nNote\nSV_POSITION\n以SV_POSITION为例，他在Vertex和Frag阶段时所代表的数据是不同的\n\n参考\n\nglsl - 为什么HLSL有语义？- 堆栈溢出 (stackoverflow.com)\nSV_POSITION 在Pixel Shader中的使用 - 知乎 (zhihu.com)\n\n","path":null},{"url":"https://yzzfo.github.io/blog/同屏渲染大量单位的一些方案/","title":"同屏渲染大量单位的一些方案","description":null,"body":"  最近遇到需要同屏渲染几百个单位的需求，在Unity中SkinnedMeshRender默认也没有合批这一说，首先就得解决一下这几百个Batch的问题。\nNVIDIA 在 GDC 曾提出，25K batchs/sec 会吃满 1GHz 的 CPU，100%的使用率。\n即有如下的估算公式\n\nAnimation-Instance\nAnimation-Instance是Unity官方的一个插件，在对SkinnedMeshRender进行合批的同时也提供了其他常用的API，接入项目时比较方便。\nAnimMap Baker\nAnimMap Baker相较与Animation-Instance做法更加激进，直接将动画烘焙进了图片之中，所有动画均用顶点动画实现，压力全放于GPU上了，且API提供的较少接入项目较为麻烦。\n参考\n\nhttps://github.com/chenjd/Render-Crowd-Of-Animated-Characters\nhttps://github.com/Unity-Technologies/Animation-Instancing\nhttps://zhuanlan.zhihu.com/p/364918045\n\n","path":null},{"url":"https://yzzfo.github.io/blog/UGUI图集笔记/","title":"UGUI图集加载问题","description":null,"body":"  之前开发UI时都使用的NGUI或FairyGUI，最近在使用UGUI时发现打完包后图集资源始终无法加载出来，在一番调试之后找到了问题所在，所以来记录一下。\nUGUI图集与NGUI的不同之处\nNGUI\n制作\nNGUI打图集时需要用户指定所需的图片之后由程序生成一张大图作为图集\n使用\nNGUI使用图片时需要先传入图集之后选择里面的图片\nUGUI\n制作\nUGUI制作图集时需要先创建Sprites Atlas文件，之后将需要的图片拖入其中即可，同一个Sprite 可以存在于多个图集之中\n使用\n直接将Sprite载入组件中即可\n问题所在\n从制作方式和使用方式中可以看出来，NGUI中资源是强关联的关系，在资源打包时是可以知道该预制体依赖哪个图集，UGUI中依赖Sprite，但Sprite是被图集依赖的对象，且可以存在于多个图集之中，这时就不能通过依赖分析的方式正确的加载图集文件了。\n解决方法\n指定依赖\n在UI基类中指定一个字段填写所依赖的图集资源，在加载资源时同步加载所需图集。\n使用SpriteAtlasManager\n当一个Sprite打包进了图集但在运行期间无法找到该图集时触发，如果Sprite在多个图集中则随机选一个图集，该方法的坏处在于异步加载时会导致图片空几帧。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/在Unity中翻转Mesh制作空气墙/","title":"在Unity中翻转Mesh制作空气墙","description":null,"body":"  有时候我们想将角色限制在一个闭合物体内部，这时我们可以通过翻转该物体的mesh达到我们期望的效果。\n前置知识\n\nunity采用左手坐标系\n对于一个三角面，通过左手螺旋得出的法线方向即为正面方向。\n在unity默认设置的情况下，对于一个三角面来说，只有正面才有碰撞检测。\n\n解决方法\n方法一：直接在blender中翻转法线即可\n方法二：通过代码翻转顶点顺序\n\n至此角色便可以在物体内部移动，在边缘时会产生正确的碰撞。\n拓展\n在遇到类似黑魂中的雾门时(单面墙)也可以采用类似的，区别在于雾门只需要一片mesh即可。\n","path":null},{"url":"https://yzzfo.github.io/blog/使用Camera生成Stencil/","title":"使用Camera生成Stencil","description":null,"body":"  有时候我们想让某个Layer上的所有物体都作为Stencil时就需要使用一个新的Camera用以渲染出对应的Stencil。\n环境\n\nUnity2020\nStandard Render Pipline\n\n相关API\n\nCamera.Render 手动调用相机的渲染，该相机必需是disable的\nCamera.SetReplacementShader 让该相机渲染的物品都使用指定Shader\nCamera.ResetReplacementShader 清除SetReplace的设置\nCamera.SetTargetBuffers 设置该相机渲染结果存到哪\nCamera.CopyFrom 复制另一个相机的设置\nGL.Clear 清除RenderTexture.active中的内容\nRenderTexture.DiscardContents 清理RenderTexture中的内容\n\n思路\n\n将用于渲染Stencil的Camera挂载于Main Camera之下\nStencil Camera使用CopyFrom复制Main Camera的设置\nStencil Camera的clearFlags设置为CameraClearFlags.Nothing\nStencil Camera的cullingMask设置为对应的LayerMask\n在Main Camera中的OnPostRender时调用Stencil Camera的Render方法生成Stencil，之所以在OnPoseRender时调用是因为此时可以获取到正确的Depth Buffer。\n\n大体代码如下\n\n二值化图片Shader\n\n其他的一些问题\nRenderTexture\n关于new和GetTemporary\n这两个API均可以获得到一个RenderTexture，区别在于GetTemporary Unity 内部保留了一个临时渲染纹理池，因此对 GetTemporary 的调用通常只返回一个已经创建的纹理（如果大小和格式匹配）。这些临时渲染纹理在几帧未使用时实际上会被破坏。\n参考资料\nRenderTexture.GetTemporary\nRenderTexture.DiscardContents\n","path":null},{"url":"https://yzzfo.github.io/blog/动画系统/","title":"动画系统","description":null,"body":"动画系统\nUnity中常用的Avatar有两种，一种是Generic另一种是Humanoid，Generic类型通常用于自定义骨骼，或者说如果有专门的一套骨骼制作则用Generic会好一些，Generic就是当纯的顶点映射，骨骼节点同名即可进行动画播放。Humanoid则采用骨骼映射的形式进行播放，通过将骨骼A映射到Unity的一个标准人体模型，通过这个中间层来映射给别的Humanoid骨骼进行播放。\n今天遇到一个问题就是现在有两个fps游戏模型素材，一个是第三人称用的射击动画，另一个是第一人称用的射击动画，他们两个都是用的同一套骨骼结构，但却无法在第一人称动画导入中使用import avatar from other导入第三人称的avatar来直接进行映射。\n\n\n第三人称和第一人称的骨骼如图所述，均为一样的结构，且模型本身也是由用一个mesh所组成，所以预想的方式为直接将第一人称的avatar设置为第三人称所生成的avatar，设置之后出现了问题，骨骼映射出现了巨大的Y向偏差，导致模型直接超出Skinmesh的渲染范围，到地底去了，如图所示\n\n\n产生该偏差的原因可能是第一人称动画本身就存在Hip节点的偏移，加之映射的缩放导致的\n之后选择用同一个模型进行Create From this mode操作来创建avatar\n\n\n打开第一人称模型的配置后会发现其及其混乱，这是由于第一人称的动作本身就扭曲导致的，仔细观察可以发现左边的arm都已经穿到右侧去了\n\n\n\n照着骨骼顺序将右侧的Unity标准骨骼结构填入，此处可通过保存第三人称的Mapping，在Load到第一人称简化操作，但在这里进行该操作后只能Mapping出上半身的映射，下半身没映射上去，不知是何原因，剩下一半就手动给拖进去。\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\n\n填充好节点之后就是将模型摆成T-Post，这里通常可以通过Pose -&gt; Enforce Pose来摆成T-Pose，但Enforce Pose在这次的模型中无效，应该也是由于第一人称模型过于扭曲的缘故。\n\n\n既然Enfore Pose无效那么怎么来摆T-Pose呢，由于第三人称模型和第一人称模型骨骼一模一样，而且第三人称模型并不扭曲在avatar中正规的T-Pose模型，于是我们可以去他的Avatar Config中将他的模型拷贝出来，做一个T-Pose预制体，用来将里面各个节点的坐标赋值给第一人称的avatar。\n\n\n复制Avatar工具\n\n\n\n在第一人称的Avatar Config界面中将模型拖入To中，将第三人称的T-Pose，预制体拖入From中点击Copy即可\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;\n7.在场景中查看效果，可以发现动画Y轴的偏移对了，但肩膀位置不对，没有还原出第一人称时的扭曲\n\n\n\n\n要还原扭曲就得知道通常骨骼动画是怎么做的，通常在骨骼动画中我们只会对各个关节进行旋转，通过旋转来达到位移，也就是说骨骼是不会拉伸的。但在第一人称的动画中，我们可以发现，这肩膀是拉伸了的，也就是说，关节不但可以旋转，还位移了，这中东西在Generic动画系统中并没什么问题，应该Generic仅仅就是映射点，并不管其他的东西，但在Humanoid中默认骨骼是不允许位移的，这是就得开启Translation DoF选项，也就是开启位移这个自由度。第一人称和第三人称均要开启。\n\n\n\n\nHumanoid的原理测试\n假设我们有两个Humanoid的Avatar A和B 均为正规的T-Pose，现在我们想让B来播放A的动作，即A映射到B身上去，正常情况下B将正常播放B的动作，此时我们将A的Avatar的根节点向后转一转，即后仰个20度并保存，此时将会导致B前倾20度，这是由于A和B均通过Unity的中间骨骼即Avatar进行映射，可能是如下过程，由于A当前设置后仰20度的状态为他的T-Pose，即标准状态，但动画中A还是直立的，所以从T-Pose到动画中的状态需要A进行前倾20度，于是乎A要完成这个动作就变成了前倾20度并完成该动画片段，将这条指令映射到B上就导致B前倾了20度。\n同样我们不改动A，来改动B，将B的Avatar前倾20度，最终结果将是B前倾20度，这是因为前倾20度就是B的标准状态，一切动作都是依照标准状态来做的，那么A在直立时做的标准动作，到了B这就是B前倾20度来做这动作。\n关于Copy avatar from other 和 Create from this的猜测，估计Avatar中记录了骨骼的长度映射关系，对于不同的第三人称模型，使用同一个avatar均没问题，这便可以排除骨骼中的位置旋转的影响，他们唯一没变的就是骨骼长度，而第一人称由于骨骼拉伸，这也导致骨骼与第三人称不匹配，所以推测avatar保存的是骨骼长度映射关系，由于这个关系导致了偏移，在上面的案例中若同时开启DoF，使用Copy的动画将会有个很巨大的放大效果，估计也是这个原因导致的。\n\n","path":null},{"url":"https://yzzfo.github.io/blog/GPU Instance/","title":"GPU Instance","description":null,"body":"最近稍微接触了一些GPU Instance特此记录一下\n在顶点片段着色器内使用GPU Instance还是比较简单的，只需要把对应属性声明方式改成GPU Instance的声明方式即可。\n\n但在GPU Instance中不支持使用Texture2D作为Instance属性，解决方法是使用Texture2DArray,将Index作为Instance属性，默认情况下Texture2DArray会生成minimap深度，所以离远了会变原色，需要在生成时进行代码设置。\n参考资料\nhttps://www.cnblogs.com/hont/p/7258615.html\nhttps://docs.unity3d.com/Manual/GPUInstancing.html\n","path":null},{"url":"https://yzzfo.github.io/blog/Unity中的同步异步/","title":"Unity中的同步异步","description":null,"body":"最近看接触xlua时发现一个挺有意思的例子,该例子中将原本的异步逻辑变为了同步逻辑,xlua中的实现是基于lua协程，于是我也想试一试在C#中实现类似的功能，lua协程简单来看也就是改变了调度顺序而已，看起来就像将异步方法放yeild中回调后续内容一样，在C#中类似的概念就是async和await，Unity在2017后就支持了C#中的async和await关键字，于是开始尝试着使用这两个关键字去实现这种功能。\nasync和await\n使用规则\n\n\nasync\n\n\n\nawait\nawait属于编译范畴的内容，可以被await的对象要符合一下条件\n\n存在一个GetAwaiter方法，该方法可以是对象自身的也可以是拓展方法，返回一个Awaiter对象\n\nAwaiter对象也是一个编译范畴的概念，也要符合如下条件\n\n继承INotifyCompletion接口\n存在一个GetResult()方法，返回类型不限\n存在一个IsCompleted的bool变量或属性\n\n\n\n\n\n一个基本的例子\n\n\n\nawait的调用逻辑\n先从await的调用逻辑看起\n\nC#中实现xlua的asyncTosync\n通过await的调用逻辑就不难发现，他其实和lua协程基本一样，await也不过是个委托封装器，专门把后续代码封装成委托的一个关键词罢了，那么思路就变成了通过await将后续方法注册给对应要等待的回调\n伪代码\n\n实现线程同步\nUnity中经常要进行线程同步操作，比如常用的事件模型，若想在网络回调中使用则需要在其中加入线程同步操作，通常来说都是维护一个任务队列之类的东西来进行同步，但通过awiat可以很容易实现线程切换。\nawait线程切换本质也就是把下文委托传递给不同线程去调用。\n\n主线程\n\n线程池\n线程池思路也和上变一样，就是改变OnCompleted中的调用线程而已。\n\nC#中Task的一些东西\nTask是C#中自带的一些Await实现，他们大都执行时在调用时的SynchronizationContext.Current中，也有一些比如await Task.Delay(10)改变线程，究其原因在于Delay是采用另一线程来执行计数的，如果不是另一个线程那么也就阻塞本线程其他的东西了，那么async也就没什么意义了。\n参考资料\nhttps://www.jacksondunstan.com/articles/4918\nhttps://gametorrahod.com/unity-and-async-await/\n","path":null},{"url":"https://yzzfo.github.io/blog/Selenium的使用/","title":"Selenium的使用","description":null,"body":"Selenium的使用\nSelenium虽然以前就接触过，但从未在Liunx服务器上去使用过，故在此记录一下在Linux下踩到的坑。\n安装\n既然是服务器上运行，那就还是使用Docker来安装比较方便了。Docker中提供了多种镜像，这里选择standalone-chrome就好，开箱即用，更多说明参考docker-selenium。\n详细的Docker安装就不做赘述，这里使用Drone CI来使用Selenium，所以阐述下在Drone CI 2.0中的使用。\n\n\n参考\n\n设置shm大小\n\n\n\n使用\n在Golang中使用github.com/tebeka/selenium这个库操作Selenium，使用Chrome版的Selenium进行如下操作\n\n\n参考\n\nhttps://stackoverflow.com/a/53970825\n\n\n\n注意事项\nSelenium中输出的所谓只有本地链接才能使用WebDriver等报错一样的日志，仅仅是提示作用，在Docker中执行并没任何问题，无需理会。\n","path":null},{"url":"https://yzzfo.github.io/blog/在Unity中使用Golang/","title":"在Unity中使用Golang","description":null,"body":"在Unity中使用Golang\n最近用Golang写了一些工具，于是就想着能不能移植到Unity中使用，众所周知Golang可以很方便的跨平台编译也可以和C交互，而Unity也是可以和C交互的，都可以通过动态链接库的形式进行连接，于是乎开始尝试在Unity中使用Golang的库。\n在Golang中编译链接库是使用CGO进行编译的，这就导致不能像编译普通Golang程序一样轻松跨平台，需要解决如下几点:\n\n安装指定平台的GCC和G++\n启用CGO\n设置目标架构和系统\n设置使用的GCC和G++\n\n安装GCC和G++\n\n对于Win来说有3种途径: Mingw，MSys2，tdm-gcc，前两种由于网络原因并不怎么好安装，即便安装了也还存在一些坑需要配置，个人感觉对于Golang来说tdm-gcc是最好的选择。\nLinux, 我这边使用的Ubuntu系统，其具体安装方式就是直接apt\n\nAndroid虽然也是Linux系统但他不能直接用Linux的库，需要使用NDK进行编译才能使用，在Win下安装NDK，采用NDK中的编译器去编译,安装NDK后设置环境变量NDKROOT和%NDKROOT%\\toolchains\\llvm\\prebuilt\\windows-x86_64\\bin\n\n\n设置Golang\n以安卓为例，设置armv7架构的安卓\n\nCompile\n接下来就是编译了\ngo build -buildmode=c-shared -o libv2free.so v2free.go\n编译导出的名字很重要，libxxx.so xxx为库名,如果直接导出xxx.so会报找不到Dll的错误，原因看一篇博文是说Android中查找库是按照这种命名规范来找的。\n接下来就是Unity的调用了\n将so或dll，拖入unity中后设置好他们正确的属性，比如运行的平台，架构等等，这样Unity才可以正确的编译，在Editor中，运行调用的是本地架构的dll，如果只有安卓没有本地架构的dll那就只能安卓测试了。对于安卓来说，设置好项目里的Android API与导出的对应，或者说导出的时候设置的与项目一致，否则可能Crash。\n调用方式如Golang编译一文中所述,接上后就能正常使用了。\n踩到的坑\n感觉像是Unity缓存或者设置的问题，在老项目中编译的安卓会各种闪退，关闭增量GC又好一些，继续关闭多线程渲染，反正各种方法试过还是会出现概率闪退问题，logcat查了调用堆栈指向了GC Crash属实看不懂了，重新开了个Unity导出就好了，感觉以后遇到奇怪问题还是重开个项目试试比较好。\n调试\n安卓ADB调试，在2019中可以下载Logcat插件了，对于安卓ADB调试十分方便，对于ADB的Crash堆栈可以通过IDA和Il2CppDumper两个东西对应着查看，但也可以用更方便的方式，导出在Build时勾选symbols.zip以及各种Debug的东西，这样配合Logcat插件就很舒服了。\n参考资料\n\nCGO交叉编译\nAndroid闪退\n找不到 Runtime CGO\n通过解析libil2cpp.so文件查看Android Crash崩溃原因\n将Go代码编译成动态链接库，android通过JNI调用\nAndroid使用Golang代替C/C++进行Native开发\n\n","path":null},{"url":"https://yzzfo.github.io/blog/UnityEditor/","title":"UnityEditor","description":null,"body":"UnityEditor\n大体流程\n指令形\n类似win上的刷新按钮，点击即执行一个固定的功能\n\n\n交互形\n这种一般就是自定窗口的形式\n\n常用的一些API\n\nUI控件\n\n控件基本存放在GUILayout和EditorGUILayout中，后者就是多个自动布局而已，EditorGUILayout中有的控件GUILayout都有，反之却不成立，所以在EditorGUILayout找不到东西是可以去GUILayout看看，比如Button组件\n文件选择框，UnityEditor自带的APIEditorUtility.OpenFilePanel只能选择单个文件，所以可以使用第三方的插件,该插件需要开启.Net4.x\n\n\n状态相关的API UnityEditor.EditorApplication  如是否正在编译\n资源相关的API AssetDatabase  如资源刷新，资源路径\nPlayerSetting相关的API UnityEditor.PlayerSettings 如宏定义\n编译相关 UnityEditor.Compilation.CompilationPipeline 如重新编译脚本\n工具类API EditorUtility PrefabUtility 等一系列Utility结尾的API，具体参考文档\n回调事件 UnityEditor.Callbacks包含事件属性，在函数上加上对应事件属性即可，可以用来build或complile时的IL注入\n\n","path":null},{"url":"https://yzzfo.github.io/blog/游戏中的算法/","title":"游戏中的算法","description":null,"body":"Shader算法\n画函数图像\n\n\n\n\n两种不同方式下的smooth函数区别\n两者都做到了 （-0.01，0.01）区间范围内的显示，但Plot1的中单个Smooth长度为0.02，而Plot2中单个Smooth长度为0.01这是两者的一种差别。即Plot1是基于原本区间进行的变化操作，而Plot2则是通过两个不同区间的smooth合并而成的操作。\nRGB和HSV转换\nFrom RGB to HSV in OpenGL GLSL - Stack Overflow\nBlog: Fast branchless RGB to HSV conversion in GLSL – Lol Engine\n灰度值计算\n\nSobel边缘检测\n\nShader画正多边形\n\n\n\n\n\n\nShader噪声\nIntroduction of Noise – 淺談雜訊 – 阿祥的開發日常 (wordpress.com)\nNoise, a Unity C# Tutorial (catlikecoding.com)\nThe Book of Shaders: Noise\nGLSL Noise Algorithms (github.com)\n噪声的艺术 - xiaOp的博客 (xiaoiver.github.io)\n常规算法\n波函数坍缩\n","path":null},{"url":"https://yzzfo.github.io/blog/变换矩阵/","title":"变换矩阵","description":null,"body":"\n\n矩阵变换的基本层次结构\n\n透视变换射影变换\n\n仿射变换\n线性变换\n\n旋转\n缩放\n\n\n\n\n\n\n\n矩阵各项的含义(可视化模型)\n$\n\\begin{bmatrix}\na &amp; b &amp; o_{x}\\\nc &amp; d &amp; o_{y}\\\np_{x} &amp; p_{y} &amp; 1\n\\end{bmatrix} \\\n$\n\n该三维矩阵作用于二维平面时其各部分含义分别为:\n\n线性变换\n$\n\\begin{bmatrix}\na &amp; b\\\nc &amp; d\n\\end{bmatrix} \\\n$\n平移变换\n$\n\\begin{bmatrix}\no_{x}\\\no_{y}\n\\end{bmatrix} \\\n$\n透视变换\n$\n\\begin{bmatrix}\np_{x} &amp; p_{y}\n\\end{bmatrix} \\\n$\n\n\n\n\n\n三维空间中的变换矩阵\n$\n\\begin{bmatrix}\na &amp; b &amp; c &amp; o_{x}\\\nd &amp; e &amp; f &amp; o_{y}\\\ng &amp; h &amp; i &amp; o_{z}\\\np_{x} &amp; p_{y} &amp; p_{z} &amp; 1\n\\end{bmatrix} \\\n$\n\n性质同作用域二维平面的三维矩阵一样\n\n\n\n函数组合\nRsl - Using Smoothstep (fundza.com)\nEasing Functions Cheat Sheet (easings.net)\n工具\n\nMathcha\nGeogebra\n\n","path":null},{"url":"https://yzzfo.github.io/blog/Shader 笔记/","title":"Shader 笔记","description":null,"body":"为什么有时候能看到类似float3*float2\n\n这里的乘法是逐分量的乘法，也就是说，每个分量都分别乘以对应的值。例如，float3(a,b,c) * float2(x,y) 等价于 float3(a_x,b_y,c)。\n\n如何把NDC空间下的坐标转换成屏幕空间下的UV坐标呢？\n\n要把NDC空间下的坐标转换成屏幕空间下的UV坐标，可以用以下公式：\nxuv = (xndc + 1) / 2\nyuv = (yndc + 1) / 2\n其中，xndc和yndc是NDC空间下的坐标，xuv和yuv是屏幕空间下的UV坐标。这个公式是把[-1, 1]范围内的NDC坐标映射到[0, 1]范围内的UV坐标。\n\nComputeScreenPos和NDC下UV的区别\nUnity Shader中的ComputeScreenPos函数 - 知乎 (zhihu.com)\nComputeScreenPos是Unity shader提供的一个内置函数，它可以根据顶点位置计算出屏幕坐标。它返回一个float4，其中xy分量是屏幕坐标，w分量是齐次坐标。要得到UV坐标，可以用xy除以w\n通过ComputeScreenPos计算而来的屏幕坐标用其算出的UV和NDC空间下转换的UV有一些区别。主要是因为ComputeScreenPos考虑了不同平台上的投影参数，而NDC空间下转换的UV没有考虑这些因素\n\n通过SV_POSITION计算UV\n\nComputeScreenPos 应该在Vertex中计算\n在Frag中计算时发现通过用其计算的结果来算uv并不正确，但在Vertex阶段计算，然后在Frag阶段去算uv是正确的，原因在此。\n计算Screen UV的例子\n\n通过Screen Positon计算世界坐标\n\nGL.GetGPUProjectionMatrix的含义\nOpenGL-like（OpenGL and OpenGL ES）和Direct3D-like（Direct3D, Metal and consoles）对Clip space的表达是不一样的，这会导致projectionMatrix会不一样，这也就是Unity提供GL.GetGPUProjectionMatrix的原因，GL.GetGPUProjectionMatrix会将Camera.projectionMatrix转换为当前GPU平台对应的表达\n\n\nUnity Shaderlab- transform from screen space to world space\n从NDC（归一化的设备坐标）坐标转换到世界坐标要点\n\n内置着色器变量\n一些常用变量\nSV_POSITION\n\nxy 屏幕坐标\nz 深度值，同ZBuffer中存储的格式一样\nw clip space下的w，在Unity中同View Space下的z\n\n_ProjectionParams\n\nx 用于判断y是否需要翻转\n\n_ScreenParams\n\nxy 屏幕大小\n\nShader指令\nAlphaTest\n\nAlphaTest选项\n\nGEqual\nEqual\nNotEqual\nLess\nLequal\nAlways\nNever\n\n\n\n\nStencil\n\nBlend混合\n\nBlend选项\n\nSrc\n\nSrcColor\nSrcAlpha\nOne MinusSrcColor\nOneMinusSrcAlpha\n\n\nDst\n\nDstColor\nDstAlpha\nOneMinusDstColor\nOneMinusDstAlpha\n\n\nOne\nZero\n\n\nBlendOp选项\n\nAdd\nSub\nRevSub\nMin\nMax\n\n\nBlend的等式(SourceRGBA*Something) + (DestRGBA*Something)``BlendOp即用于替换等式之间的+如Min((SourceRGBA*Something),(DestRGBA*Something))\n\nColorMask\n\nGrabPass\nGrabPass{ _CustomTex }抓取屏幕内容并命名为_CustomTex的贴图 若未设置 _CustomTex 则默认名字为 _GrabTexture\nShader固定管线\n对于固定渲染管线Combine中也可以在其Pass中定义诸如AlphaTest，Stencil，Blend这样的指令并生效，使用方法同其他方式一致。\nUnityShader之固定管线命令Combine纹理混合【Shader资料4】 - 威少小二orz - 博客园 (cnblogs.com)\n额外资料\nUnity rendering order 整理筆記 (twsiyuan.com)\n源码探析Mask、Rect Mask2D与Sprite Mask的异同 (renkaikai.com)\n","path":null}]